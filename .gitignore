import pandas as pd
from sklearn.model_selection import train_test_split
import numpy as np
import matplotlib.pyplot as plt
from sklearn.neighbors import KNeighborsClassifier
import seaborn as sns

iris = pd.read_csv('IRIS.csv')
iris.head()

iris.info()

iris.isnull().sum()

iris.species.unique()

Z = iris['species'].map({'Iris-setosa' : 0,
                'Iris-versicolor' : 1,
                'Iris-virginica' : 2})
print(Z.head())

tmp = iris
g = sns.pairplot(tmp, hue='species', markers='+')
plt.show()

sns.boxplot(x = "species", y = "petal_length", data = iris);

sns.boxplot(x = "species", y = "sepal_length", data = iris);

corr = iris.corr()
sns.heatmap(corr, annot=True, cmap='RdPu')
plt.show()

sns.lineplot(x="sepal_width", y="sepal_length", data=iris)
plt.title("sepal_length en fonction sepal_width")
plt.show()
sns.lineplot(x="petal_length", y="petal_width", data=iris)
plt.title("petal_width en fonction petal_length")
plt.show()

sns.lineplot(x="sepal_width", y="petal_width", data=iris)
plt.title("petal_length en fonction sepal_width")
plt.show()


sns.lineplot(x="sepal_length", y="petal_length", data=iris)
plt.title("petal_length en fonction sepal_length")
plt.show()

iris.drop(['species'], inplace=True, axis=1)
iris.head()

data = pd.concat([iris, Z], axis = 1)
data.head()

from sklearn.model_selection import train_test_split
X=data[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']]  # Features
y=data['species']

# Split dataset into training set and test set
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)# 70% training and 30% test

from sklearn.ensemble import RandomForestClassifier

#Create a Gaussian Classifier
clf=RandomForestClassifier(n_estimators=100)

#Train the model using the training sets y_pred=clf.predict(X_test)
clf.fit(X_train,y_train)

y_pred=clf.predict(X_test)

#Import scikit-learn metrics module for accuracy calculation
from sklearn import metrics
# Model Accuracy, how often is the classifier correct?
print("Accuracy:",metrics.accuracy_score(y_test, y_pred))

from sklearn.metrics import confusion_matrix, classification_report, accuracy_score
conf_mat = confusion_matrix(y_test,y_pred)
print(conf_mat)

rep = classification_report(y_test, y_pred)
print(rep)

sns.set()
sns.heatmap(conf_mat, annot=True, fmt="d", cmap="RdPu", xticklabels=["Iris-setosa", "Iris-versicolor", "Iris-virginica"], yticklabels=["Iris-setosa", "Iris-versicolor", "Iris-virginica"])
plt.title("Confusion Matrix")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.show()

feature_names = X.columns.values.tolist()
print(feature_names)

features = pd.Series(clf.feature_importances_,index=feature_names).sort_values(ascending=False)
features

sns.barplot(x=features, y=features.index)
plt.xlabel('characteristics values')
plt.ylabel('characteristics names')
plt.title("characteristics visualisation")
plt.legend()
plt.show()

from sklearn.model_selection import learning_curve
N, train_score, val_score = learning_curve(clf, X_train, y_train, train_sizes= np.linspace(0.1,1,10), cv=5)

N, train_score, val_score = learning_curve(clf, X_train, y_train, train_sizes= np.linspace(0.1,1,10), cv=5)
print(N)
plt.plot(N, train_score.mean(axis=1), label='train')
plt.plot(N, val_score.mean(axis=1), label='validation')
plt.xlabel('train_sizes')
plt.legend();
